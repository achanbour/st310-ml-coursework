---
title: "Seminar notebook"
author: "Anastasia Chanbour"
date: "08/10/2021"
output: html_document
---
# Loading the required packages

```{r}
library(tidyverse)
library(gapminder)
library(broom) #broom package takes the messy output of built-in functions in R, such as lm,#nls, or t.test, and turns them into tidy tables
theme_set(theme_minimal(base_size = 10))   #theme_set overides default ggplot theme
library(gapminder)
library(plotly)
```

# Linear regression

## Simple linear regression

### Estimation

**Task**
1. Filter year=2007 from the gapminder data and call the data frame object gm2007.
2. Create a regression object called model_lm that regresses lifeEXp on gdpPercap for 2007 data
3. Output the estimated coefficients, intercept and slope, only

```{r}
gm2007 <- gapminder %>% filter(year == 2007)
model_lm <- lm(data = gm2007, lifeExp ~ gdpPercap)
coef(model_lm)
```


### Demo dplyr::summarise function

Summarise function displays the coefficient estimates in the regression model


- hat_beta1 = `cor(x,y) * sd(y) / sd(x)`
- hat_beta0 = mean(y) - hat_beta1 * mean(x)
- Regression line passes through `(mean(x), mean(y))`


```{r}
#output: correlation, sd, mean(x), mean(y), estimated intercept and slope coefficient using formula
gm2007 %>%
  summarize(cor_xy=cor(gdpPercap, lifeExp),
            sd_x = sd(gdpPercap),
            sd_y = sd(lifeExp),
            mean_x = mean(gdpPercap),
            mean_y = mean(lifeExp),
            hat_beta1 = cor_xy/sd_x*sd_y,
            hat_beta0 = mean_y - hat_beta1*mean_x)
```

### Inference

```{r}
#Use summary() to obtain basic output of regression
summary(model_lm)
```

(ISLR eq 3.8) p.66

`se(beta hat) = sigma / sqrt(sum((x - mean(x))^2))`

Estimated by:

`se(beta hat) = sigma hat / sqrt(sum((x - mean(x))^2))`

where (ISLR 3.15) p.69:

`sigma hat = RSE = sqrt( RSS / (n-2) )`


```{r}
#Using augment() to extract residuals, compute the estimated se of the slope parameter by
#obtaining 1. RSS 2. MSE = (RSS/(n-p)) 3. estimated S.E of hat beta1
augment(model_lm) %>%
  summarize(RSS = sum(.resid^2),
            MSE = RSS /(n()-2),
            SE = sqrt(MSE)/sqrt(sum((gdpPercap - mean(gdpPercap))^2)))
```

### Model diagnostics

```{r}
#glance: Construct a single row summary "glance" of a model, fit, or other object
#CODE
glance(model_lm)
```

"Portion of variance in outcome **explained** by simple linear regression model"

$$
R^2 = \text{cor}(x,y)^2
$$

```{r}
#compute correlation squared between gdpPercap and lifeExp
#CODE
cor(gm2007$gdpPercap, gm2007$lifeExp)^2
```

$$
R^2 = 1 - \frac{\text{RSS}}{\text{TSS}}
$$


```{r}
#using residuals from augment(), obtain values of RSS, TSS, and R2
#CODE
augment(model_lm) %>%
  summarize(RSS = sum(.resid^2),
            TSS = sum((lifeExp - mean(lifeExp))^2),
            R2 = 1 - RSS/TSS)


```



### Diagnostic plots

Idea: look for patterns in residuals, which could indicate systematic errors (bias)

Outliers vs influential points: influential points affect the slope of the model line

```{r}
#Plot residuals vs gdpPercap, using residuals from augment()
#CODE
par(mfrow=c(1,3))
plot(model_lm, which = c(1,2,4)) #plot.lm is plot on a regression generates 6 plots
```
There is a pattern in residuals. Suggets that the relationship is non-linear


Other diagnostics:

- Checking for (approximate) normality with quantile-quantile plot
- Checking for influential observations

[Cook's distance](https://en.wikipedia.org/wiki/Cook%27s_distance), `cooksd` in the plots, measures how much the predictions for all other observations change if we leave out one observation

Point with high `cooksd` values
